import gradio as gr
import sounddevice as sd
import sherpa_onnx
import numpy as np
from queue import Queue
import threading

# -------------------- æ¨¡å‹åˆå§‹åŒ– --------------------
# MODEL_DIR = "sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20"
MODEL_DIR = "sherpa-onnx-streaming-zipformer-model"

def create_recognizer():
    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    tokens = f"{MODEL_DIR}/tokens.txt"
    encoder = f"{MODEL_DIR}/encoder-epoch-99-avg-1.onnx"
    decoder = f"{MODEL_DIR}/decoder-epoch-99-avg-1.onnx"
    joiner = f"{MODEL_DIR}/joiner-epoch-99-avg-1.onnx"

    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = sherpa_onnx.OnlineRecognizer.from_transducer(
        tokens=tokens,
        encoder=encoder,
        decoder=decoder,
        joiner=joiner,
        num_threads=1,
        sample_rate=16000,
        feature_dim=80,
        enable_endpoint_detection=True,
        rule1_min_trailing_silence=2.4,
        rule2_min_trailing_silence=1.2,
        rule3_min_utterance_length=300,
        decoding_method="greedy_search",
        provider="cpu",
    )
    return recognizer

# -------------------- å…¨å±€å˜é‡ --------------------
recognizer = create_recognizer()  # åˆå§‹åŒ–æ¨¡å‹
result_queue = Queue()            # ç»“æœé˜Ÿåˆ—
audio_stream = None               # éŸ³é¢‘æµå¯¹è±¡
stream = None                     # sherpa-onnxæµ

# -------------------- éŸ³é¢‘å¤„ç†é€»è¾‘ --------------------
def audio_callback(indata, frames, time, status):
    """å®æ—¶éŸ³é¢‘æµå›è°ƒå‡½æ•°"""
    global stream
    if status:
        print(f"éŸ³é¢‘æµé”™è¯¯: {status}")
    
    # å°†numpyæ•°ç»„è½¬æ¢ä¸ºlist[float]
    samples = indata.reshape(-1).astype(np.float32).tolist()
    
    # æµå¼å¤„ç†éŸ³é¢‘æ•°æ®
    stream.accept_waveform(16000, samples)  # æ³¨æ„é‡‡æ ·ç‡éœ€ä¸æ¨¡å‹ä¸€è‡´
    while recognizer.is_ready(stream):
        recognizer.decode_stream(stream)
    
    # è·å–è¯†åˆ«ç»“æœ
    result = recognizer.get_result(stream)
    if result:
        result_queue.put(result)  # å°†ç»“æœæ¨é€åˆ°é˜Ÿåˆ—

# -------------------- Gradioäº¤äº’é€»è¾‘ --------------------
def start_recording():
    """å¼€å§‹å½•éŸ³"""
    global audio_stream, stream
    stream = recognizer.create_stream()  # åˆ›å»ºæ–°çš„è¯†åˆ«æµ
    try:
        audio_stream = sd.InputStream(
            samplerate=16000,       # å¿…é¡»ä¸æ¨¡å‹é‡‡æ ·ç‡ä¸€è‡´
            channels=1,
            callback=audio_callback,
            dtype='float32'
        )
        audio_stream.start()
        return "å½•éŸ³å·²å¼€å§‹ï¼Œè¯·è¯´è¯..."
    except Exception as e:
        return f"å¯åŠ¨å¤±è´¥: {str(e)}"

def stop_recording():
    """åœæ­¢å½•éŸ³"""
    global audio_stream
    if audio_stream:
        audio_stream.stop()
        audio_stream.close()
        audio_stream = None
    return "å½•éŸ³å·²åœæ­¢"

def update_result():
    """å®æ—¶æ›´æ–°è¯†åˆ«ç»“æœåˆ°ç•Œé¢"""
    while True:
        if not result_queue.empty():
            yield result_queue.get()
        else:
            yield "ç­‰å¾…è¯­éŸ³è¾“å…¥..."
        time.sleep(0.1)  # æ§åˆ¶æ›´æ–°é¢‘ç‡

# -------------------- æ„å»ºGradioç•Œé¢ --------------------
with gr.Blocks(title="å®æ—¶è¯­éŸ³è¯†åˆ«") as demo:
    gr.Markdown("# åŸºäºSherpa-onnxçš„å®æ—¶è¯­éŸ³è¯†åˆ«")
    
    # æ§ä»¶
    result_box = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False, streaming=True)
    start_btn = gr.Button("ğŸ¤ å¼€å§‹å½•éŸ³", variant="primary")
    stop_btn = gr.Button("â¹ åœæ­¢å½•éŸ³", variant="secondary")
    
    # äº‹ä»¶ç»‘å®š
    start_btn.click(
        fn=start_recording,
        outputs=result_box,
        api_name="start_recording"
    )
    stop_btn.click(
        fn=stop_recording,
        outputs=result_box,
        api_name="stop_recording"
    )
    
    # å®æ—¶æ›´æ–°
    demo.load(
        fn=update_result,
        outputs=result_box,
        every=0.1,  # æ¯0.1ç§’æ›´æ–°ä¸€æ¬¡
    )

# -------------------- å¯åŠ¨åº”ç”¨ --------------------
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
