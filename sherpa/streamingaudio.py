import gradio as gr
import numpy as np
from sherpa_onnx import OnlineRecognizer, OnlineStream

# -------------------- æ¨¡å‹åˆå§‹åŒ– --------------------
# MODEL_DIR = "sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20"
MODEL_DIR = "sherpa-onnx-streaming-zipformer-model"
def create_recognizer():
    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    tokens = f"{MODEL_DIR}/tokens.txt"
    encoder = f"{MODEL_DIR}/encoder-epoch-99-avg-1.onnx"
    decoder = f"{MODEL_DIR}/decoder-epoch-99-avg-1.onnx"
    joiner = f"{MODEL_DIR}/joiner-epoch-99-avg-1.onnx"
    # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ï¼ˆéœ€ä¸sherpa-onnxå…¼å®¹ï¼‰
    recognizer = OnlineRecognizer.from_transducer(
        tokens=tokens,
        encoder=encoder,
        decoder=decoder,
        joiner=joiner,
        num_threads=1,
        sample_rate=48000,
        feature_dim=80,
    )
    return recognizer

recognizer = create_recognizer()

# -------------------- æµå¼å¤„ç†é€»è¾‘ --------------------
def transcribe(stream_state, new_chunk):
    sr, audio_data = new_chunk
    # stream = recognizer.create_stream()
    # åˆå§‹åŒ–æˆ–è·å–å½“å‰è¯†åˆ«æµ
    if stream_state is None:
        stream = recognizer.create_stream()
    else:
        stream = stream_state

    # å¤„ç†éŸ³é¢‘å—ï¼ˆè½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼ï¼‰
    audio_data = audio_data.astype(np.float32)
    if audio_data.ndim > 1:  # è½¬å•å£°é“
        audio_data = np.mean(audio_data, axis=1)
    audio_data /= np.max(np.abs(audio_data))  # å½’ä¸€åŒ–
    
    # æµå¼è¯†åˆ«
    stream.accept_waveform(sr, audio_data.tolist())
    while recognizer.is_ready(stream):
        recognizer.decode_stream(stream)
    result = recognizer.get_result(stream)
    print("è¯­éŸ³è¯†åˆ«ç»“æœï¼š" + result)
    # è¿”å›æ›´æ–°åçš„æµçŠ¶æ€å’Œè¯†åˆ«ç»“æœ
    return stream, result or ""

# -------------------- Gradio ç•Œé¢ --------------------
demo = gr.Interface(
    fn=transcribe,
    inputs=[
        gr.State(),  # ç”¨äºä¿å­˜è¯†åˆ«æµçŠ¶æ€
        gr.Audio(
            sources=["microphone"],
            streaming=True,  # å¯ç”¨æµå¼æ¨¡å¼
            type="numpy"
        )
    ],
    outputs=[
        gr.State(),  # æ›´æ–°åçš„æµçŠ¶æ€
        gr.Textbox(label="å®æ—¶è¯†åˆ«ç»“æœ")
    ],
    live=True,  # å®æ—¶å¤„ç†è¾“å…¥
    title="æµå¼è¯­éŸ³è¯†åˆ« (Sherpa-onnx)",
    description="ç‚¹å‡»éº¦å…‹é£å¹¶è¯´è¯ï¼Œå®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ"
)

# with gr.Blocks(title="æµå¼è¯­éŸ³è¯†åˆ«") as demo:
#     gr.Markdown("## ğŸ¤ æµå¼è¯­éŸ³è¯†åˆ« (Sherpa-onnx)")
#     gr.Markdown("ç‚¹å‡»éº¦å…‹é£æŒ‰é’®å¼€å§‹è¯´è¯ï¼Œè¯†åˆ«ç»“æœå°†å®æ—¶æ˜¾ç¤ºä¸‹æ–¹")

#     stream_state = gr.State()
#     # è¾“å…¥åŒºåŸŸï¼ˆä¸Šæ–¹ï¼‰
#     with gr.Row():
#         state_input = gr.State()  # éšè—çŠ¶æ€ç»„ä»¶
#         audio_input = gr.Audio(
#             sources=["microphone"],
#             # streaming=True,
#             type="numpy"
#         )
        
    
#     # è¾“å‡ºåŒºåŸŸï¼ˆä¸‹æ–¹ï¼‰
#     with gr.Row():
#         state_output = gr.State()  # éšè—çŠ¶æ€ç»„ä»¶
#         result_output = gr.Textbox(
#             label="å®æ—¶è¯†åˆ«ç»“æœ"
#         )
    


#     # äº‹ä»¶ç»‘å®šï¼ˆä¿æŒå®æ—¶æµå¼å¤„ç†ï¼‰
#     audio_input.stream(
#         fn=transcribe,
#         inputs=[state_input, audio_input],
#         outputs=[state_output, result_output]
#     )

demo.launch(share=True, server_name="0.0.0.0", server_port=8989)
